{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "from pettingzoo.test import api_test\n",
    "import pettingzoo\n",
    "import gymnasium as gym\n",
    "\n",
    "from sb3_contrib import MaskablePPO\n",
    "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "\n",
    "from lib.briscola_env.briscola_env import BriscolaEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting API test\n",
      "Passed API test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tim/src/briscola-py/.venv/lib/python3.11/site-packages/pettingzoo/test/api_test.py:242: UserWarning: Observation space for each agent probably should be gymnasium.spaces.box or gymnasium.spaces.discrete\n",
      "  warnings.warn(\n",
      "/home/tim/src/briscola-py/.venv/lib/python3.11/site-packages/pettingzoo/test/api_test.py:140: UserWarning: Observation is not a NumPy array\n",
      "  warnings.warn(\"Observation is not a NumPy array\")\n",
      "/home/tim/src/briscola-py/.venv/lib/python3.11/site-packages/pettingzoo/test/api_test.py:660: UserWarning: Environment has not defined a render() method\n",
      "  warnings.warn(\"Environment has not defined a render() method\")\n"
     ]
    }
   ],
   "source": [
    "env = BriscolaEnv()\n",
    "api_test(env, num_cycles=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To pass into other gymnasium wrappers, we need to ensure that pettingzoo's wrappper\n",
    "# can also be a gymnasium Env. Thus, we subclass under gym.Env as well.\n",
    "class SB3ActionMaskWrapper(pettingzoo.utils.BaseWrapper, gym.Env):\n",
    "    \"\"\"Wrapper to allow PettingZoo environments to be used with SB3 illegal action masking.\"\"\"\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"Gymnasium-like reset function which assigns obs/action spaces to be the same for each agent.\n",
    "\n",
    "        This is required as SB3 is designed for single-agent RL and doesn't expect obs/action spaces to be functions\n",
    "        \"\"\"\n",
    "        super().reset(seed, options)\n",
    "\n",
    "        # Strip the action mask out from the observation space\n",
    "        self.observation_space = super().observation_space(self.possible_agents[0])[\n",
    "            \"observation\"\n",
    "        ]\n",
    "        self.action_space = super().action_space(self.possible_agents[0])\n",
    "\n",
    "        # Return initial observation, info (PettingZoo AEC envs do not by default)\n",
    "        return self.observe(self.agent_selection), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Gymnasium-like step function, returning observation, reward, termination, truncation, info.\n",
    "\n",
    "        The observation is for the next agent (used to determine the next action), while the remaining\n",
    "        items are for the agent that just acted (used to understand what just happened).\n",
    "        \"\"\"\n",
    "        current_agent = self.agent_selection\n",
    "\n",
    "        super().step(action)\n",
    "\n",
    "        next_agent = self.agent_selection\n",
    "        return (\n",
    "            self.observe(next_agent),\n",
    "            self._cumulative_rewards[current_agent],\n",
    "            self.terminations[current_agent],\n",
    "            self.truncations[current_agent],\n",
    "            self.infos[current_agent],\n",
    "        )\n",
    "\n",
    "    def observe(self, agent):\n",
    "        \"\"\"Return only raw observation, removing action mask.\"\"\"\n",
    "        return super().observe(agent)[\"observation\"]\n",
    "\n",
    "    def action_mask(self):\n",
    "        \"\"\"Separate function used in order to access the action mask.\"\"\"\n",
    "        return super().observe(self.agent_selection)[\"action_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_fn(env):\n",
    "    return env.action_mask()\n",
    "\n",
    "def train(\n",
    "    steps: int = 10_000, seed: int | None = 0, **env_kwargs\n",
    "):\n",
    "    # Train a single model to play as each agent in a cooperative Parallel environment\n",
    "    env = BriscolaEnv()\n",
    "    env = SB3ActionMaskWrapper(env)\n",
    "    env.reset(seed=seed)\n",
    "    env = ActionMasker(env, mask_fn)\n",
    "\n",
    "    print(f\"Starting training on {str(env.metadata)}.\")\n",
    "    model = MaskablePPO(MaskableActorCriticPolicy, env, verbose=1)\n",
    "    model.set_random_seed(seed)\n",
    "    model.learn(total_timesteps=steps)\n",
    "    model.save(f\"{env.unwrapped.metadata.get('name')}_{time.strftime('%Y%m%d-%H%M%S')}\")\n",
    "\n",
    "    print(\"Model has been saved.\")\n",
    "    print(f\"Finished training on {str(env.unwrapped.metadata['name'])}.\\n\")\n",
    "    env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on {'render_modes': []}.\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 40       |\n",
      "|    ep_rew_mean     | 589      |\n",
      "| time/              |          |\n",
      "|    fps             | 281      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 608          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 233          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035692202 |\n",
      "|    clip_fraction        | 0.00435      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.947       |\n",
      "|    explained_variance   | 0.00301      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+04     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00969     |\n",
      "|    value_loss           | 3.76e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 627          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 223          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028592455 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.943       |\n",
      "|    explained_variance   | 0.00259      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.26e+04     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00761     |\n",
      "|    value_loss           | 4.22e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 630          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 218          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 37           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025456424 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.937       |\n",
      "|    explained_variance   | 0.00126      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.88e+04     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.00709     |\n",
      "|    value_loss           | 4.04e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 635          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 214          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 47           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028724202 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.931       |\n",
      "|    explained_variance   | 0.000434     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.87e+04     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00763     |\n",
      "|    value_loss           | 4.01e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 40        |\n",
      "|    ep_rew_mean          | 642       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 211       |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 58        |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0029089 |\n",
      "|    clip_fraction        | 0.00151   |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.922    |\n",
      "|    explained_variance   | 0.000459  |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.29e+04  |\n",
      "|    n_updates            | 50        |\n",
      "|    policy_gradient_loss | -0.00765  |\n",
      "|    value_loss           | 4.02e+04  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 650          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 211          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032528597 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.918       |\n",
      "|    explained_variance   | 0.00037      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.04e+04     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00758     |\n",
      "|    value_loss           | 3.98e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40          |\n",
      "|    ep_rew_mean          | 656         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 208         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002785804 |\n",
      "|    clip_fraction        | 0.00117     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.908      |\n",
      "|    explained_variance   | 0.00017     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.07e+04    |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    value_loss           | 3.97e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 667          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021895487 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.9         |\n",
      "|    explained_variance   | 0.000135     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.96e+04     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    value_loss           | 3.99e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 669          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 98           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027161986 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.888       |\n",
      "|    explained_variance   | 0.000126     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+04     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00637     |\n",
      "|    value_loss           | 3.94e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40          |\n",
      "|    ep_rew_mean          | 680         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 207         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002024885 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.877      |\n",
      "|    explained_variance   | 9.34e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.95e+04    |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    value_loss           | 3.94e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40          |\n",
      "|    ep_rew_mean          | 681         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 206         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003885612 |\n",
      "|    clip_fraction        | 0.00488     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.869      |\n",
      "|    explained_variance   | 4.6e-05     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.95e+04    |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00791    |\n",
      "|    value_loss           | 4.04e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 698          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 128          |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017853639 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.856       |\n",
      "|    explained_variance   | 4.59e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.96e+04     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    value_loss           | 3.73e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 709          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025988156 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.852       |\n",
      "|    explained_variance   | 6.44e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.21e+04     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    value_loss           | 4.13e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 706          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030664192 |\n",
      "|    clip_fraction        | 0.00459      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.837       |\n",
      "|    explained_variance   | 5.99e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+04     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    value_loss           | 3.84e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 710          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 159          |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029935688 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.817       |\n",
      "|    explained_variance   | 2.19e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+04     |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    value_loss           | 3.86e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 709          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027654476 |\n",
      "|    clip_fraction        | 0.00376      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.815       |\n",
      "|    explained_variance   | 2.95e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8e+04      |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    value_loss           | 3.79e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 711          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 179          |\n",
      "|    total_timesteps      | 36864        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025011627 |\n",
      "|    clip_fraction        | 0.00146      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.808       |\n",
      "|    explained_variance   | 2.71e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.62e+04     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    value_loss           | 3.67e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 724          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025359562 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.8         |\n",
      "|    explained_variance   | 7.82e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+04     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    value_loss           | 3.62e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 715          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022296933 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.798       |\n",
      "|    explained_variance   | 0.000323     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.69e+04     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    value_loss           | 3.67e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 705          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 207          |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030549285 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.778       |\n",
      "|    explained_variance   | 0.0165       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.88e+04     |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.006       |\n",
      "|    value_loss           | 3.35e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 719          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 217          |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030567634 |\n",
      "|    clip_fraction        | 0.00869      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.775       |\n",
      "|    explained_variance   | 0.127        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+04      |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    value_loss           | 3.29e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 40         |\n",
      "|    ep_rew_mean          | 729        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 207        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 227        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00222588 |\n",
      "|    clip_fraction        | 0.00254    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.765     |\n",
      "|    explained_variance   | 0.163      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.9e+04    |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0052    |\n",
      "|    value_loss           | 3.44e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40          |\n",
      "|    ep_rew_mean          | 720         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 206         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002122223 |\n",
      "|    clip_fraction        | 0.00225     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.747      |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+04    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    value_loss           | 3.36e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 730          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 247          |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024808503 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.738       |\n",
      "|    explained_variance   | 0.244        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.4e+04      |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    value_loss           | 3.06e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 737          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 256          |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012359621 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.733       |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.49e+04     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 3.34e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 734          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 266          |\n",
      "|    total_timesteps      | 55296        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024103466 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.727       |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+04     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    value_loss           | 3.13e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 739          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 276          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024604541 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.725       |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.67e+04     |\n",
      "|    n_updates            | 270          |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    value_loss           | 3.07e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40          |\n",
      "|    ep_rew_mean          | 745         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 207         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 286         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002229863 |\n",
      "|    clip_fraction        | 0.00259     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.718      |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.46e+04    |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    value_loss           | 3.06e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 744          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 207          |\n",
      "|    iterations           | 30           |\n",
      "|    time_elapsed         | 296          |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021331701 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.704       |\n",
      "|    explained_variance   | 0.304        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.31e+04     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    value_loss           | 3.06e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 40         |\n",
      "|    ep_rew_mean          | 756        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 206        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 306        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00163309 |\n",
      "|    clip_fraction        | 0.000342   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.705     |\n",
      "|    explained_variance   | 0.318      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.55e+04   |\n",
      "|    n_updates            | 300        |\n",
      "|    policy_gradient_loss | -0.00382   |\n",
      "|    value_loss           | 2.93e+04   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 746          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 32           |\n",
      "|    time_elapsed         | 316          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018591629 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.697       |\n",
      "|    explained_variance   | 0.31         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.52e+04     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    value_loss           | 3.08e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40          |\n",
      "|    ep_rew_mean          | 740         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 206         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 326         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002607571 |\n",
      "|    clip_fraction        | 0.0061      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.695      |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17e+04    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    value_loss           | 2.66e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 756          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 336          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021374526 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.699       |\n",
      "|    explained_variance   | 0.353        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.39e+04     |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    value_loss           | 2.82e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 744          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 347          |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017646657 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.687       |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.47e+04     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    value_loss           | 2.76e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 739          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 356          |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018791547 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.685       |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.24e+04     |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    value_loss           | 2.57e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 743          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 367          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029435847 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.679       |\n",
      "|    explained_variance   | 0.4          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.25e+04     |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.006       |\n",
      "|    value_loss           | 2.5e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 745          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 377          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026580277 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.683       |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.17e+04     |\n",
      "|    n_updates            | 370          |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    value_loss           | 2.42e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 757          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 206          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 387          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030769852 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.669       |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.22e+04     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 2.4e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 758          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 40           |\n",
      "|    time_elapsed         | 397          |\n",
      "|    total_timesteps      | 81920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018702184 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.666       |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.39e+04     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    value_loss           | 2.6e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 736          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 408          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020409015 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.663       |\n",
      "|    explained_variance   | 0.433        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+04      |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    value_loss           | 2.35e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 737          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 418          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028455306 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.655       |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19e+04     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    value_loss           | 2.08e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 750          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 428          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016645165 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.651       |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.42e+03     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00426     |\n",
      "|    value_loss           | 2.18e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40          |\n",
      "|    ep_rew_mean          | 760         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 205         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 439         |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001788581 |\n",
      "|    clip_fraction        | 0.00298     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.654      |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+04    |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    value_loss           | 2.17e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 755          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 204          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 449          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017127761 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.649       |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.08e+04     |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    value_loss           | 2.22e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 747          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 204          |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 459          |\n",
      "|    total_timesteps      | 94208        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022830472 |\n",
      "|    clip_fraction        | 0.0063       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.636       |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.33e+03     |\n",
      "|    n_updates            | 450          |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    value_loss           | 1.99e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 750          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 204          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 470          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028161479 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.639       |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02e+04     |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    value_loss           | 1.96e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 40         |\n",
      "|    ep_rew_mean          | 761        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 204        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 479        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00240272 |\n",
      "|    clip_fraction        | 0.00645    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.64      |\n",
      "|    explained_variance   | 0.528      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.06e+03   |\n",
      "|    n_updates            | 470        |\n",
      "|    policy_gradient_loss | -0.00564   |\n",
      "|    value_loss           | 1.93e+04   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40           |\n",
      "|    ep_rew_mean          | 769          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 205          |\n",
      "|    iterations           | 49           |\n",
      "|    time_elapsed         | 489          |\n",
      "|    total_timesteps      | 100352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022931744 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.636       |\n",
      "|    explained_variance   | 0.551        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.85e+03     |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    value_loss           | 1.98e+04     |\n",
      "------------------------------------------\n",
      "Model has been saved.\n",
      "Finished training on briscola.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train(steps=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_action_mask(player, num_games=100):\n",
    "    # Evaluate a trained agent vs a random agent\n",
    "    env = BriscolaEnv()\n",
    "\n",
    "    print(\n",
    "        f\"Starting evaluation vs random agents. Trained agent will play as {env.possible_agents[player]}.\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        latest_policy = max(\n",
    "            glob.glob(f\"{env.metadata['name']}*.zip\"), key=os.path.getctime\n",
    "        )\n",
    "    except ValueError:\n",
    "        print(\"Policy not found.\")\n",
    "        exit(0)\n",
    "    print(\"using\", latest_policy)\n",
    "    model = MaskablePPO.load(latest_policy)\n",
    "\n",
    "    scores = {agent: 0 for agent in env.possible_agents}\n",
    "    total_rewards = {agent: 0 for agent in env.possible_agents}\n",
    "    for i in range(num_games):\n",
    "        env.reset(seed=i)\n",
    "\n",
    "        for agent in env.agent_iter():\n",
    "            obs, reward, termination, truncation, info = env.last()\n",
    "\n",
    "            # Separate observation and action mask\n",
    "            observation, action_mask = obs.values()\n",
    "\n",
    "            if termination or truncation:\n",
    "                winner = max(env.rewards, key=env.rewards.get)\n",
    "                scores[winner] += env.rewards[\n",
    "                    winner\n",
    "                ]  # only tracks the largest reward (winner of game)\n",
    "                # Also track negative and positive rewards (penalizes illegal moves)\n",
    "                for a in env.possible_agents:\n",
    "                    total_rewards[a] += env.rewards[a]\n",
    "                # List of rewards by round, for reference\n",
    "                break\n",
    "            else:\n",
    "                if agent != env.possible_agents[player]:\n",
    "                    act = env.action_space(agent).sample(action_mask)\n",
    "                else:\n",
    "                    # Note: PettingZoo expects integer actions # TODO: change chess to cast actions to type int?\n",
    "                    act = int(\n",
    "                        model.predict(\n",
    "                            observation, action_masks=action_mask, deterministic=True\n",
    "                        )[0]\n",
    "                    )\n",
    "            env.step(act)\n",
    "    env.close()\n",
    "\n",
    "    player_results = []\n",
    "    print(\"Winrates:\")\n",
    "    for p in env.possible_agents:\n",
    "        if sum(scores.values()) == 0:\n",
    "            winrate = 0\n",
    "        else:\n",
    "            winrate = scores[p] / sum(scores.values())\n",
    "        print(f\"\\t{p}: {winrate*100}%`\")\n",
    "        print(f\"\\t{total_rewards[p]}\")\n",
    "        player_results.append({\"winrate\": winrate})\n",
    "    return player_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing position 0 ---\n",
      "Starting evaluation vs random agents. Trained agent will play as player_0.\n",
      "using briscola_20250427-150451.zip\n",
      "Winrates:\n",
      "\tplayer_0: 28.72978513400653%`\n",
      "\t68393\n",
      "\tplayer_1: 22.403386227317593%`\n",
      "\t58409\n",
      "\tplayer_2: 26.204666818515427%`\n",
      "\t64393\n",
      "\tplayer_3: 22.662161820160453%`\n",
      "\t58805\n",
      "--- Testing position 1 ---\n",
      "Starting evaluation vs random agents. Trained agent will play as player_1.\n",
      "using briscola_20250427-150451.zip\n",
      "Winrates:\n",
      "\tplayer_0: 28.030140343342218%`\n",
      "\t66837\n",
      "\tplayer_1: 20.1160895873072%`\n",
      "\t55758\n",
      "\tplayer_2: 27.510326794083095%`\n",
      "\t67444\n",
      "\tplayer_3: 24.343443275267486%`\n",
      "\t59961\n",
      "--- Testing position 2 ---\n",
      "Starting evaluation vs random agents. Trained agent will play as player_2.\n",
      "using briscola_20250427-150451.zip\n",
      "Winrates:\n",
      "\tplayer_0: 28.94637271718293%`\n",
      "\t67690\n",
      "\tplayer_1: 19.842220764806783%`\n",
      "\t53706\n",
      "\tplayer_2: 27.862349914236706%`\n",
      "\t69105\n",
      "\tplayer_3: 23.349056603773587%`\n",
      "\t59499\n",
      "--- Testing position 3 ---\n",
      "Starting evaluation vs random agents. Trained agent will play as player_3.\n",
      "using briscola_20250427-150451.zip\n",
      "Winrates:\n",
      "\tplayer_0: 29.83894416140981%`\n",
      "\t68028\n",
      "\tplayer_1: 20.683159930723235%`\n",
      "\t55250\n",
      "\tplayer_2: 27.58555301316006%`\n",
      "\t68489\n",
      "\tplayer_3: 21.8923428947069%`\n",
      "\t58233\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for position in range(4):\n",
    "\tprint(f\"--- Testing position {position} ---\")\n",
    "\tresults.append(eval_action_mask(position, num_games=1_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
